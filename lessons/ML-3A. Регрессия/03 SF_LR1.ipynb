{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import load_boston\n",
    "from sklearn.metrics import mean_squared_error, f1_score, accuracy_score, roc_curve, roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Линейная регрессия. Реализация"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(506, 13)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = load_boston()\n",
    "data['data'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".. _boston_dataset:\n",
      "\n",
      "Boston house prices dataset\n",
      "---------------------------\n",
      "\n",
      "**Data Set Characteristics:**  \n",
      "\n",
      "    :Number of Instances: 506 \n",
      "\n",
      "    :Number of Attributes: 13 numeric/categorical predictive. Median Value (attribute 14) is usually the target.\n",
      "\n",
      "    :Attribute Information (in order):\n",
      "        - CRIM     per capita crime rate by town\n",
      "        - ZN       proportion of residential land zoned for lots over 25,000 sq.ft.\n",
      "        - INDUS    proportion of non-retail business acres per town\n",
      "        - CHAS     Charles River dummy variable (= 1 if tract bounds river; 0 otherwise)\n",
      "        - NOX      nitric oxides concentration (parts per 10 million)\n",
      "        - RM       average number of rooms per dwelling\n",
      "        - AGE      proportion of owner-occupied units built prior to 1940\n",
      "        - DIS      weighted distances to five Boston employment centres\n",
      "        - RAD      index of accessibility to radial highways\n",
      "        - TAX      full-value property-tax rate per $10,000\n",
      "        - PTRATIO  pupil-teacher ratio by town\n",
      "        - B        1000(Bk - 0.63)^2 where Bk is the proportion of blacks by town\n",
      "        - LSTAT    % lower status of the population\n",
      "        - MEDV     Median value of owner-occupied homes in $1000's\n",
      "\n",
      "    :Missing Attribute Values: None\n",
      "\n",
      "    :Creator: Harrison, D. and Rubinfeld, D.L.\n",
      "\n",
      "This is a copy of UCI ML housing dataset.\n",
      "https://archive.ics.uci.edu/ml/machine-learning-databases/housing/\n",
      "\n",
      "\n",
      "This dataset was taken from the StatLib library which is maintained at Carnegie Mellon University.\n",
      "\n",
      "The Boston house-price data of Harrison, D. and Rubinfeld, D.L. 'Hedonic\n",
      "prices and the demand for clean air', J. Environ. Economics & Management,\n",
      "vol.5, 81-102, 1978.   Used in Belsley, Kuh & Welsch, 'Regression diagnostics\n",
      "...', Wiley, 1980.   N.B. Various transformations are used in the table on\n",
      "pages 244-261 of the latter.\n",
      "\n",
      "The Boston house-price data has been used in many machine learning papers that address regression\n",
      "problems.   \n",
      "     \n",
      ".. topic:: References\n",
      "\n",
      "   - Belsley, Kuh & Welsch, 'Regression diagnostics: Identifying Influential Data and Sources of Collinearity', Wiley, 1980. 244-261.\n",
      "   - Quinlan,R. (1993). Combining Instance-Based and Model-Based Learning. In Proceedings on the Tenth International Conference of Machine Learning, 236-243, University of Massachusetts, Amherst. Morgan Kaufmann.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(data['DESCR'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1. Реализация линейной регрессии с использованием матричных операций"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Линейная регрессия выражается следующей зависимостью:\n",
    "$$y=X\\theta+\\epsilon,$$\n",
    "где $X$ — матрица объекты-признаки, $y$ — вектор целевых значений, соответствующих $X$, $\\theta$ — параметр линейной регрессии, $\\epsilon$ — некоторый шум."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Из данного следует выражение для $\\theta$ как:\n",
    "$$X^Ty=X^TX\\theta \\rightarrow \\theta=(X^TX)^{-1}X^Ty$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Реализуем выражение для $\\theta$ с помощью операций линейной алгебры библиотеки Numpy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ЗАДАЧА Реализовать функцию, осуществляющую матричные операции для получения theta\n",
    "def linreg_linear(X, y):\n",
    "    theta = np.linalg.inv(X.T@X)@X.T@y\n",
    "  \n",
    "    return theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Подготовить данные\n",
    "\n",
    "X, y = data['data'], data['target']\n",
    "\n",
    "X = np.hstack([np.ones(X.shape[0])[:, np.newaxis], X])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Вычислить параметр theta\n",
    "theta = linreg_linear(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14,)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "theta.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Сделать предсказания для тренировочной выборки\n",
    "y_pred = X.dot(theta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_regression_metrics(y_true, y_pred):\n",
    "    mse = mean_squared_error(y_true, y_pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "    print(f'MSE = {mse:.2f}, RMSE = {rmse:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE = 21.89, RMSE = 4.68\n"
     ]
    }
   ],
   "source": [
    "# Посчитать значение ошибок MSE и RMSE для тренировочных данных\n",
    "print_regression_metrics(y, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(y);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Разбить выборку на train/valid, вычислить theta,\n",
    "# сделать предсказания и посчитать ошибки MSE и RMSE\n",
    "\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.2)\n",
    "theta = linreg_linear(X_train, y_train)\n",
    "y_pred = X_valid.dot(theta)\n",
    "y_train_pred = X_train.dot(theta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE = 33.29, RMSE = 5.77\n",
      "MSE = 19.37, RMSE = 4.40\n"
     ]
    }
   ],
   "source": [
    "print_regression_metrics(y_valid, y_pred)\n",
    "print_regression_metrics(y_train, y_train_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE = 21.89, RMSE = 4.68\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "lr = LinearRegression()\n",
    "lr.fit(X,y)\n",
    "y_pred = lr.predict(X)\n",
    "print_regression_metrics(y, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2. Реализация линейной регрессии с использованием методов оптимизации"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для реализации линейной регрессии с помощью методов оптимизации будем использовать функцию ошибки **среднего квадратичного** ([Mean Squared Error](https://en.wikipedia.org/wiki/Mean_squared_error)), которая является выпуклой функцией в n-мерном пространстве $\\mathbb{R}^n$ и в общем виде выглядит следующим образом:\n",
    "$$MSE = \\frac{1}{n} * \\sum_{i=1}^{n}{(y_i - a(x_i))^2}.$$\n",
    "Здесь $x_i$ — вектор-признак $i$-го объекта обучающей выборки, $y_i$ — истинное значение для $i$-го объекта, $a(x)$ — алгоритм, предсказывающий для данного объекта $x$ целевое значение, $n$ — кол-во объектов в выборке."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В случае линейной регрессии $MSE$ представляется как:\n",
    "$$MSE(X, y, \\theta) = \\frac{1}{2n} * \\sum_{i=1}^{n}{(y_i - \\theta^Tx_i)^2} = \\frac{1}{2n} \\lVert{y - X\\theta}\\rVert_{2}^{2}=\\frac{1}{2n} (y - X\\theta)^T(y - X\\theta),$$\n",
    "где $\\theta$ — параметр модели линейной регрессии, $X$ — матрица объекты-признаки, $y$ - вектор истинных значений, соответствующих $X$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Возьмем первый вариант представления функции ошибки и посчитаем ее градиент по параметру $\\theta$, предварительно переименовав $MSE$ в $L$:\n",
    "$$L=\\frac{1}{2n} * \\sum_{i=1}^{n}{(y_i - \\theta^Tx_i)^2}$$\n",
    "$$\\nabla L = \\frac{1}{n}\\sum_{i=1}^{n}{(\\theta^Tx_i - y_i) \\cdot x_i} = \\frac{1}{n}X^T(X\\theta - y)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Исходя из полученного выражения градиента, реализуем алгоритм градиентного спуска:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Реализовать функцию вычисления градиента функции MSE\n",
    "\n",
    "def calc_mse_gradient(X, y, theta):\n",
    "    n = X.shape[0]\n",
    "    grad = 1. / n * X.transpose().dot(X.dot(theta) - y)\n",
    "    \n",
    "    return grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Реализовать функцию, осуществляющую градиентный шаг\n",
    "# (функция должна содержать параметр величины шага alpha - learning rate)\n",
    "\n",
    "def gradient_step(theta, theta_grad, alpha):\n",
    "    return theta - alpha * theta_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Реализовать функцию цикла градиентного спуска с доп. параметрами\n",
    "# начального вектора theta и числа итераций\n",
    "\n",
    "def optimize(X, y, grad_func, start_theta, alpha, n_iters):\n",
    "    theta = start_theta.copy()\n",
    "    \n",
    "    for i in range(n_iters):\n",
    "        theta_grad = grad_func(X, y, theta)\n",
    "        theta = gradient_step(theta, theta_grad, alpha)\n",
    "    \n",
    "    return theta\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Разбить таблицу данных на матрицы X и y\n",
    "X, y = data['data'], data['target']\n",
    "\n",
    "# Добавить фиктивный столбец единиц (bias линейной модели)\n",
    "X = np.hstack([np.ones(X.shape[0])[:, np.newaxis], X])\n",
    "m = X.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Оптимизировать параметр линейной регрессии theta на всех данных\n",
    "theta = optimize(X, y, calc_mse_gradient, np.ones(m), 0.001, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([7.41647399e+246, 3.32349992e+247, 7.39564172e+247, 8.96295209e+247,\n",
       "       5.07578059e+245, 4.22030567e+246, 4.63094053e+247, 5.29083888e+248,\n",
       "       2.65643383e+247, 8.19991211e+247, 3.27135991e+249, 1.38363846e+248,\n",
       "       2.64323053e+249, 9.88835598e+247])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  1.    ,  88.9762, 100.    ,  27.74  ,   1.    ,   0.871 ,\n",
       "         8.78  , 100.    ,  12.1265,  24.    , 711.    ,  22.    ,\n",
       "       396.9   ,  37.97  ])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Проверить максимальные значения по каждому признаку в данных\n",
    "X.max(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "B\n",
      "168.3704950393814\n"
     ]
    }
   ],
   "source": [
    "print(data['feature_names'][np.argmax(X.std(axis=0)) + 1])\n",
    "print(np.max(X.std(axis=0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Нормализовать даннные с помощью стандартной нормализации\n",
    "X, y = data['data'], data['target']\n",
    "X = (X - X.mean(axis=0)) / X.std(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.        , 9.9339306 , 3.80423444, 2.42256516, 3.66839786,\n",
       "       2.73234648, 3.55504427, 1.11749449, 3.96051769, 1.66124525,\n",
       "       1.79819419, 1.63882832, 0.44105193, 3.54877081])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Добавить фиктивный столбец единиц (bias линейной модели)\n",
    "X = np.hstack([np.ones(X.shape[0])[:, np.newaxis], X])\n",
    "X.max(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Оптимизировать theta на новых данных\n",
    "theta = optimize(X, y, calc_mse_gradient, np.ones(m), 0.01, 5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 2.25328063e+01, -9.21740195e-01,  1.07033639e+00,  1.06388396e-01,\n",
       "        6.86667316e-01, -2.05006416e+00,  2.68062168e+00,  1.40667969e-02,\n",
       "       -3.10608483e+00,  2.57511475e+00, -1.97802851e+00, -2.05725099e+00,\n",
       "        8.48690321e-01, -3.74025884e+00])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Сделать предсказания при полученных параметрах\n",
    "y_pred = X.dot(theta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE = 21.90, RMSE = 4.68\n"
     ]
    }
   ],
   "source": [
    "# Посчитать значение ошибок MSE и RMSE для тренировочных данных\n",
    "print_regression_metrics(y, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE = 27.29, RMSE = 5.22\n"
     ]
    }
   ],
   "source": [
    "# Разбить выборку на train/valid, оптимизировать theta,\n",
    "# сделать предсказания и посчитать ошибки MSE и RMSE\n",
    "\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.2)\n",
    "theta = optimize(X_train, y_train, calc_mse_gradient, np.ones(m), 0.01, 5000)\n",
    "y_pred = X_valid.dot(theta)\n",
    "\n",
    "print_regression_metrics(y_valid, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = data['data'], data['target']\n",
    "\n",
    "#X = np.hstack([np.ones(X.shape[0])[:, np.newaxis], X])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([16.82743855, 25.32322296,  8.67869991, 25.18765109, 18.10630934,\n",
       "       19.14023344, 23.04203099, 23.7905936 , 29.16285935, 31.38050107,\n",
       "       25.58719873, 17.69690178, -5.48373179, 16.71003074, 37.96691437,\n",
       "       18.28855247, 22.20550911, 18.41616683, 30.83724456,  9.22332605,\n",
       "       13.52714074, 17.0061113 , 22.57615147, 27.93721315, 34.81475855,\n",
       "       17.92425028, 31.06167782, 23.77676706, 21.11495628, 22.14702065,\n",
       "       32.28446567,  9.27755934, 35.50399184, 20.609976  , 20.37219618,\n",
       "       15.35387474, 16.86775027, 15.40250217, 18.67610678, 27.99900278,\n",
       "       32.8396572 , 22.15162523, 32.233771  , 19.49300225, 16.8458707 ,\n",
       "       25.99998058, 14.06336034, -0.28373231, 20.71069783, 24.34044694,\n",
       "       23.14835492, 25.64840404, 24.6272626 , 16.06159235,  0.8282735 ,\n",
       "       24.14508687, 17.45773278, 15.58341957, 13.67652693, 17.6013498 ,\n",
       "       22.54542491, 24.48502141, 12.70601605, 30.30994301, 36.36130084,\n",
       "       20.35742206, 26.8657976 , 40.18110643, 25.02797923, 13.30999513,\n",
       "       19.36213995, 10.86104588, 26.46667646, 29.52938205, 25.01886095,\n",
       "       16.81675187, 16.82160615, 19.78851708, 20.39900176, 25.47207946,\n",
       "       33.73242871, 16.2509323 , 23.97118229, 40.47177041, 28.29374691,\n",
       "       21.549037  , 30.1816746 , 21.44685574, 24.43331086, 30.37559701,\n",
       "       20.56831221, 27.50141941, 32.1795709 , 25.18947356, 26.43302649,\n",
       "       16.06799666, 32.83917669, 26.3179719 , 20.93268994, 30.86972959,\n",
       "       18.6224713 , 24.97625539])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE = 26.51, RMSE = 5.15\n"
     ]
    }
   ],
   "source": [
    "print_regression_metrics(y_pred, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Разбить таблицу данных на матрицы X и y\n",
    "X, y = data['data'], data['target']\n",
    "\n",
    "# Добавить фиктивный столбец единиц (bias линейной модели)\n",
    "#X = np.hstack([np.ones(X.shape[0])[:, np.newaxis], X])\n",
    "#m = X.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Оптимизировать параметр линейной регрессии theta на всех данных\n",
    "#theta = optimize(X, y, calc_mse_gradient, np.ones(m), 0.001, 100)\n",
    "#theta = optimize(X, y, calc_mse_gradient, np.ones(m), 0.001, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 2.25620630e+01, -9.58574220e-01,  1.02126647e+00, -2.87991577e-03,\n",
       "        8.79173563e-01, -1.67506676e+00,  2.56923842e+00, -1.98998919e-01,\n",
       "       -3.15457994e+00,  2.18376676e+00, -1.98769061e+00, -1.99930760e+00,\n",
       "        6.26898867e-01, -3.68807517e+00])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 88.9762, 100.    ,  27.74  ,   1.    ,   0.871 ,   8.78  ,\n",
       "       100.    ,  12.1265,  24.    , 711.    ,  22.    , 396.9   ,\n",
       "        37.97  ])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Проверить максимальные значения по каждому признаку в данных\n",
    "X.max(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PTRATIO\n",
      "168.3704950393814\n"
     ]
    }
   ],
   "source": [
    "print(data['feature_names'][np.argmax(X.std(axis=0)) + 1])\n",
    "print(np.max(X.std(axis=0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Нормализовать даннные с помощью стандартной нормализации\n",
    "X, y = data['data'], data['target']\n",
    "X = (X - X.mean(axis=0)) / X.std(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.        , 9.9339306 , 3.80423444, 2.42256516, 3.66839786,\n",
       "       2.73234648, 3.55504427, 1.11749449, 3.96051769, 1.66124525,\n",
       "       1.79819419, 1.63882832, 0.44105193, 3.54877081])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Добавить фиктивный столбец единиц (bias линейной модели)\n",
    "X = np.hstack([np.ones(X.shape[0])[:, np.newaxis], X])\n",
    "X.max(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Оптимизировать theta на новых данных\n",
    "theta = optimize(X, y, calc_mse_gradient, np.ones(m), 0.01, 5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 2.25328063e+01, -9.21740195e-01,  1.07033639e+00,  1.06388396e-01,\n",
       "        6.86667316e-01, -2.05006416e+00,  2.68062168e+00,  1.40667969e-02,\n",
       "       -3.10608483e+00,  2.57511475e+00, -1.97802851e+00, -2.05725099e+00,\n",
       "        8.48690321e-01, -3.74025884e+00])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Сделать предсказания при полученных параметрах\n",
    "y_pred = X.dot(theta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE = 21.90, RMSE = 4.68\n"
     ]
    }
   ],
   "source": [
    "# Посчитать значение ошибок MSE и RMSE для тренировочных данных\n",
    "print_regression_metrics(y, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE = 20.70, RMSE = 4.55\n"
     ]
    }
   ],
   "source": [
    "# Разбить выборку на train/valid, оптимизировать theta,\n",
    "# сделать предсказания и посчитать ошибки MSE и RMSE\n",
    "\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.2)\n",
    "theta = optimize(X_train, y_train, calc_mse_gradient, np.ones(m), 0.01, 5000)\n",
    "y_pred = X_valid.dot(theta)\n",
    "\n",
    "print_regression_metrics(y_valid, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
